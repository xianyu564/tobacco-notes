#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºå†…å®¹éªŒè¯å·¥å…·
Comprehensive content validation for tobacco notes repository
"""

import json
import yaml
import re
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import hashlib
from urllib.parse import urlparse


class ContentValidator:
    """ç»¼åˆå†…å®¹éªŒè¯å™¨"""
    
    def __init__(self, repo_root: Path = None):
        self.repo_root = repo_root or Path(__file__).resolve().parents[1]
        self.notes_dir = self.repo_root / 'notes'
        self.docs_dir = self.repo_root / 'docs'
        self.errors = []
        self.warnings = []
        self.stats = {
            'total_notes': 0,
            'valid_notes': 0,
            'categories': {},
            'validation_score': 0
        }
        
        # éªŒè¯è§„åˆ™é…ç½®
        self.validation_rules = {
            'required_fields': ['title', 'category', 'date'],
            'optional_fields': ['brand', 'rating', 'description', 'tags', 'price'],
            'categories': ['cigars', 'cigarettes', 'pipe', 'ryo', 'snus', 'ecig'],
            'date_format': r'^\d{4}-\d{2}-\d{2}$',
            'filename_format': r'^\d{4}-\d{2}-\d{2}-[a-z0-9\-]+\.md$',
            'rating_range': (0, 10),
            'max_title_length': 100,
            'max_description_length': 5000,
            'min_description_length': 50
        }
    
    def validate_all_content(self) -> Dict:
        """éªŒè¯æ‰€æœ‰å†…å®¹"""
        print("ğŸš€ å¼€å§‹ç»¼åˆå†…å®¹éªŒè¯...")
        print("=" * 50)
        
        # éªŒè¯ç¬”è®°å†…å®¹
        self._validate_notes()
        
        # éªŒè¯å›¾ç‰‡èµ„æº
        self._validate_images()
        
        # éªŒè¯æ•°æ®æ–‡ä»¶
        self._validate_data_files()
        
        # éªŒè¯é…ç½®æ–‡ä»¶
        self._validate_config_files()
        
        # è®¡ç®—éªŒè¯å¾—åˆ†
        self._calculate_validation_score()
        
        # ç”ŸæˆæŠ¥å‘Š
        return self._generate_report()
    
    def _validate_notes(self):
        """éªŒè¯ç¬”è®°å†…å®¹"""
        print("\nğŸ“ éªŒè¯ç¬”è®°å†…å®¹...")
        
        if not self.notes_dir.exists():
            self.errors.append("ç¬”è®°ç›®å½•ä¸å­˜åœ¨")
            return
        
        for category_dir in self.notes_dir.iterdir():
            if not category_dir.is_dir() or category_dir.name.startswith('.'):
                continue
                
            if category_dir.name not in self.validation_rules['categories']:
                self.warnings.append(f"æœªçŸ¥çš„åˆ†ç±»ç›®å½•: {category_dir.name}")
                continue
            
            self.stats['categories'][category_dir.name] = 0
            self._validate_category_notes(category_dir)
    
    def _validate_category_notes(self, category_dir: Path):
        """éªŒè¯åˆ†ç±»ç›®å½•ä¸‹çš„ç¬”è®°"""
        category = category_dir.name
        
        for note_file in category_dir.glob('*.md'):
            if note_file.name.startswith('TEMPLATE_'):
                continue
                
            self.stats['total_notes'] += 1
            
            # éªŒè¯æ–‡ä»¶åæ ¼å¼
            if not re.match(self.validation_rules['filename_format'], note_file.name):
                self.errors.append(f"æ–‡ä»¶åæ ¼å¼é”™è¯¯: {note_file}")
                continue
            
            # éªŒè¯ç¬”è®°å†…å®¹
            if self._validate_note_content(note_file, category):
                self.stats['valid_notes'] += 1
                self.stats['categories'][category] += 1
    
    def _validate_note_content(self, note_file: Path, category: str) -> bool:
        """éªŒè¯å•ä¸ªç¬”è®°å†…å®¹"""
        try:
            with open(note_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æå‰ç«¯matter
            frontmatter, body = self._parse_frontmatter(content)
            
            if not frontmatter:
                self.errors.append(f"ç¼ºå°‘frontmatter: {note_file}")
                return False
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            for field in self.validation_rules['required_fields']:
                if field not in frontmatter:
                    self.errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ {field}: {note_file}")
                    return False
            
            # éªŒè¯åˆ†ç±»åŒ¹é…
            if frontmatter.get('category') != category:
                self.errors.append(f"åˆ†ç±»ä¸åŒ¹é…: {note_file}")
                return False
            
            # éªŒè¯æ—¥æœŸæ ¼å¼
            date_str = frontmatter.get('date', '')
            if not re.match(self.validation_rules['date_format'], str(date_str)):
                self.errors.append(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {note_file}")
                return False
            
            # éªŒè¯æ—¥æœŸä¸æ–‡ä»¶ååŒ¹é…
            file_date = note_file.name[:10]
            if str(date_str) != file_date:
                self.errors.append(f"æ—¥æœŸä¸æ–‡ä»¶åä¸åŒ¹é…: {note_file}")
                return False
            
            # éªŒè¯æ ‡é¢˜é•¿åº¦
            title = frontmatter.get('title', '')
            if len(title) > self.validation_rules['max_title_length']:
                self.warnings.append(f"æ ‡é¢˜è¿‡é•¿: {note_file}")
            
            # éªŒè¯è¯„åˆ†
            rating = frontmatter.get('rating')
            if rating is not None:
                try:
                    rating_val = float(rating)
                    min_rating, max_rating = self.validation_rules['rating_range']
                    if not (min_rating <= rating_val <= max_rating):
                        self.errors.append(f"è¯„åˆ†è¶…å‡ºèŒƒå›´: {note_file}")
                        return False
                except (ValueError, TypeError):
                    self.errors.append(f"è¯„åˆ†æ ¼å¼é”™è¯¯: {note_file}")
                    return False
            
            # éªŒè¯å†…å®¹é•¿åº¦
            if body:
                body_length = len(body.strip())
                if body_length > self.validation_rules['max_description_length']:
                    self.warnings.append(f"å†…å®¹è¿‡é•¿: {note_file}")
                elif body_length < self.validation_rules['min_description_length']:
                    self.warnings.append(f"å†…å®¹è¿‡çŸ­: {note_file}")
            
            # éªŒè¯ç‰¹å®šåˆ†ç±»çš„å­—æ®µ
            self._validate_category_specific_fields(frontmatter, category, note_file)
            
            return True
            
        except Exception as e:
            self.errors.append(f"è¯»å–æ–‡ä»¶å¤±è´¥ {note_file}: {str(e)}")
            return False
    
    def _parse_frontmatter(self, content: str) -> Tuple[Optional[Dict], str]:
        """è§£æfrontmatter"""
        if not content.startswith('---'):
            return None, content
        
        try:
            parts = content.split('---', 2)
            if len(parts) >= 3:
                frontmatter = yaml.safe_load(parts[1])
                body = parts[2].strip()
                return frontmatter, body
        except yaml.YAMLError as e:
            self.errors.append(f"YAMLè§£æé”™è¯¯: {str(e)}")
        
        return None, content
    
    def _validate_category_specific_fields(self, frontmatter: Dict, category: str, note_file: Path):
        """éªŒè¯åˆ†ç±»ç‰¹å®šå­—æ®µ"""
        # é›ªèŒ„ç‰¹å®šéªŒè¯
        if category == 'cigars':
            size = frontmatter.get('size')
            if size and not re.match(r'^\d+x\d+$', str(size)):
                self.warnings.append(f"é›ªèŒ„å°ºå¯¸æ ¼å¼å»ºè®®ä½¿ç”¨ 'é•¿åº¦xç¯å¾„': {note_file}")
        
        # é¦™çƒŸç‰¹å®šéªŒè¯
        elif category == 'cigarettes':
            pack_type = frontmatter.get('pack_type')
            if pack_type and pack_type not in ['soft', 'hard', 'box']:
                self.warnings.append(f"åŒ…è£…ç±»å‹å»ºè®®ä½¿ç”¨æ ‡å‡†å€¼: {note_file}")
        
        # çƒŸæ–—ç‰¹å®šéªŒè¯
        elif category == 'pipe':
            tobacco_type = frontmatter.get('tobacco_type')
            if tobacco_type and tobacco_type not in ['virginia', 'burley', 'oriental', 'latakia', 'perique', 'aromatic']:
                self.warnings.append(f"çƒŸè‰ç±»å‹å»ºè®®ä½¿ç”¨æ ‡å‡†å€¼: {note_file}")
    
    def _validate_images(self):
        """éªŒè¯å›¾ç‰‡èµ„æº"""
        print("\nğŸ–¼ï¸  éªŒè¯å›¾ç‰‡èµ„æº...")
        
        images_dir = self.docs_dir / 'images'
        if not images_dir.exists():
            self.warnings.append("å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨")
            return
        
        for img_file in images_dir.rglob('*'):
            if img_file.is_file():
                self._validate_single_image(img_file)
    
    def _validate_single_image(self, img_file: Path):
        """éªŒè¯å•ä¸ªå›¾ç‰‡æ–‡ä»¶"""
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        valid_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.gif', '.svg'}
        if img_file.suffix.lower() not in valid_extensions:
            self.warnings.append(f"ä¸æ¨èçš„å›¾ç‰‡æ ¼å¼: {img_file}")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        try:
            file_size = img_file.stat().st_size
            if file_size > 2 * 1024 * 1024:  # 2MB
                self.warnings.append(f"å›¾ç‰‡æ–‡ä»¶è¿‡å¤§ (>2MB): {img_file}")
        except OSError:
            self.errors.append(f"æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶: {img_file}")
    
    def _validate_data_files(self):
        """éªŒè¯æ•°æ®æ–‡ä»¶"""
        print("\nğŸ“Š éªŒè¯æ•°æ®æ–‡ä»¶...")
        
        data_dir = self.docs_dir / 'data'
        if not data_dir.exists():
            self.warnings.append("æ•°æ®ç›®å½•ä¸å­˜åœ¨")
            return
        
        # éªŒè¯JSONæ•°æ®æ–‡ä»¶
        for json_file in data_dir.glob('*.json'):
            self._validate_json_file(json_file)
    
    def _validate_json_file(self, json_file: Path):
        """éªŒè¯JSONæ–‡ä»¶"""
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # éªŒè¯ç‰¹å®šçš„æ•°æ®æ–‡ä»¶
            if json_file.name == 'contributors.json':
                self._validate_contributors_data(data, json_file)
            elif json_file.name == 'latest.json':
                self._validate_latest_data(data, json_file)
                
        except json.JSONDecodeError as e:
            self.errors.append(f"JSONæ ¼å¼é”™è¯¯ {json_file}: {str(e)}")
        except Exception as e:
            self.errors.append(f"è¯»å–JSONæ–‡ä»¶å¤±è´¥ {json_file}: {str(e)}")
    
    def _validate_contributors_data(self, data: Dict, file_path: Path):
        """éªŒè¯è´¡çŒ®è€…æ•°æ®"""
        required_fields = ['last_updated', 'total_contributors', 'contributors']
        for field in required_fields:
            if field not in data:
                self.errors.append(f"è´¡çŒ®è€…æ•°æ®ç¼ºå°‘å­—æ®µ {field}: {file_path}")
        
        contributors = data.get('contributors', [])
        for i, contributor in enumerate(contributors):
            if not isinstance(contributor, dict):
                self.errors.append(f"è´¡çŒ®è€…æ•°æ®æ ¼å¼é”™è¯¯ [ç´¢å¼•{i}]: {file_path}")
                continue
            
            required_contributor_fields = ['username', 'display_name', 'total_contributions']
            for field in required_contributor_fields:
                if field not in contributor:
                    self.errors.append(f"è´¡çŒ®è€…ç¼ºå°‘å­—æ®µ {field} [ç´¢å¼•{i}]: {file_path}")
    
    def _validate_latest_data(self, data: Dict, file_path: Path):
        """éªŒè¯æœ€æ–°ç¬”è®°æ•°æ®"""
        if not isinstance(data, list):
            self.errors.append(f"æœ€æ–°ç¬”è®°æ•°æ®åº”ä¸ºæ•°ç»„: {file_path}")
            return
        
        for i, note in enumerate(data):
            if not isinstance(note, dict):
                self.errors.append(f"ç¬”è®°æ•°æ®æ ¼å¼é”™è¯¯ [ç´¢å¼•{i}]: {file_path}")
                continue
            
            required_note_fields = ['title', 'category', 'date', 'slug']
            for field in required_note_fields:
                if field not in note:
                    self.errors.append(f"ç¬”è®°ç¼ºå°‘å­—æ®µ {field} [ç´¢å¼•{i}]: {file_path}")
    
    def _validate_config_files(self):
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        print("\nâš™ï¸  éªŒè¯é…ç½®æ–‡ä»¶...")
        
        # éªŒè¯.htaccess
        htaccess_file = self.docs_dir / '.htaccess'
        if htaccess_file.exists():
            self._validate_htaccess(htaccess_file)
        
        # éªŒè¯robots.txt
        robots_file = self.docs_dir / 'robots.txt'
        if robots_file.exists():
            self._validate_robots_txt(robots_file)
        
        # éªŒè¯sitemap.xml
        sitemap_file = self.docs_dir / 'sitemap.xml'
        if sitemap_file.exists():
            self._validate_sitemap(sitemap_file)
    
    def _validate_htaccess(self, htaccess_file: Path):
        """éªŒè¯.htaccessé…ç½®"""
        try:
            with open(htaccess_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«åŸºæœ¬çš„é‡å†™è§„åˆ™
            if 'RewriteEngine' not in content:
                self.warnings.append(".htaccessç¼ºå°‘RewriteEngineé…ç½®")
            
            # æ£€æŸ¥ç¼“å­˜é…ç½®
            if 'ExpiresByType' not in content and 'mod_expires' not in content:
                self.warnings.append(".htaccessç¼ºå°‘ç¼“å­˜é…ç½®")
                
        except Exception as e:
            self.errors.append(f"è¯»å–.htaccesså¤±è´¥: {str(e)}")
    
    def _validate_robots_txt(self, robots_file: Path):
        """éªŒè¯robots.txt"""
        try:
            with open(robots_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if 'User-agent:' not in content:
                self.warnings.append("robots.txtç¼ºå°‘User-agentå£°æ˜")
            
            if 'Sitemap:' not in content:
                self.warnings.append("robots.txtç¼ºå°‘SitemapæŒ‡å‘")
                
        except Exception as e:
            self.errors.append(f"è¯»å–robots.txtå¤±è´¥: {str(e)}")
    
    def _validate_sitemap(self, sitemap_file: Path):
        """éªŒè¯sitemap.xml"""
        try:
            import xml.etree.ElementTree as ET
            tree = ET.parse(sitemap_file)
            root = tree.getroot()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰URLæ¡ç›®
            urls = root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}url')
            if len(urls) == 0:
                self.warnings.append("sitemap.xmlæ²¡æœ‰URLæ¡ç›®")
            
            # æ£€æŸ¥URLæ ¼å¼
            for url in urls[:5]:  # æ£€æŸ¥å‰5ä¸ªURL
                loc = url.find('.//{http://www.sitemaps.org/schemas/sitemap/0.9}loc')
                if loc is not None:
                    url_text = loc.text
                    if not url_text or not url_text.startswith(('http://', 'https://')):
                        self.errors.append(f"sitemap.xmlåŒ…å«æ— æ•ˆURL: {url_text}")
                        
        except Exception as e:
            self.errors.append(f"éªŒè¯sitemap.xmlå¤±è´¥: {str(e)}")
    
    def _calculate_validation_score(self):
        """è®¡ç®—éªŒè¯å¾—åˆ†"""
        total_issues = len(self.errors) + len(self.warnings)
        max_score = 100
        
        if total_issues == 0:
            self.stats['validation_score'] = max_score
        else:
            # é”™è¯¯æƒé‡æ›´é«˜
            error_weight = 10
            warning_weight = 2
            
            penalty = (len(self.errors) * error_weight) + (len(self.warnings) * warning_weight)
            self.stats['validation_score'] = max(0, max_score - penalty)
    
    def _generate_report(self) -> Dict:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\n" + "=" * 50)
        print("ğŸ“Š éªŒè¯æŠ¥å‘Š")
        print("=" * 50)
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"ğŸ“ æ€»ç¬”è®°æ•°: {self.stats['total_notes']}")
        print(f"âœ… æœ‰æ•ˆç¬”è®°æ•°: {self.stats['valid_notes']}")
        print(f"ğŸ¯ éªŒè¯å¾—åˆ†: {self.stats['validation_score']}/100")
        
        # åˆ†ç±»ç»Ÿè®¡
        if self.stats['categories']:
            print("\nğŸ“ åˆ†ç±»ç»Ÿè®¡:")
            for category, count in self.stats['categories'].items():
                print(f"   {category}: {count} ç¯‡")
        
        # é”™è¯¯å’Œè­¦å‘Š
        if self.errors:
            print(f"\nâŒ é”™è¯¯ ({len(self.errors)}):")
            for error in self.errors[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                print(f"   â€¢ {error}")
            if len(self.errors) > 10:
                print(f"   ... è¿˜æœ‰ {len(self.errors) - 10} ä¸ªé”™è¯¯")
        
        if self.warnings:
            print(f"\nâš ï¸  è­¦å‘Š ({len(self.warnings)}):")
            for warning in self.warnings[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªè­¦å‘Š
                print(f"   â€¢ {warning}")
            if len(self.warnings) > 10:
                print(f"   ... è¿˜æœ‰ {len(self.warnings) - 10} ä¸ªè­¦å‘Š")
        
        # æ€»ç»“
        if len(self.errors) == 0:
            if len(self.warnings) == 0:
                print("\nğŸ‰ æ‰€æœ‰å†…å®¹éªŒè¯é€šè¿‡ï¼")
            else:
                print("\nâœ… éªŒè¯é€šè¿‡ï¼Œä½†æœ‰ä¸€äº›å»ºè®®æ”¹è¿›çš„åœ°æ–¹")
        else:
            print("\nâŒ éªŒè¯å¤±è´¥ï¼Œè¯·ä¿®æ­£é”™è¯¯åé‡è¯•")
        
        return {
            'success': len(self.errors) == 0,
            'stats': self.stats,
            'errors': self.errors,
            'warnings': self.warnings,
            'timestamp': datetime.now().isoformat()
        }


def main():
    """ä¸»å‡½æ•°"""
    validator = ContentValidator()
    result = validator.validate_all_content()
    
    # ä¿å­˜éªŒè¯æŠ¥å‘Š
    report_file = validator.repo_root / 'docs' / 'data' / 'validation-report.json'
    report_file.parent.mkdir(exist_ok=True)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return result['success']


if __name__ == '__main__':
    import sys
    success = main()
    sys.exit(0 if success else 1)