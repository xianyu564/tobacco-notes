name: Comprehensive Validation

on:
  push:
    branches: [ master, develop, feature/*, chore/* ]
  pull_request:
    branches: [ master, develop ]
  workflow_dispatch:

jobs:
  content-validation:
    runs-on: ubuntu-latest
    name: Content Validation
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r tools/requirements.txt
        
    - name: Validate notes content
      run: |
        python tools/validate_content.py
        
    - name: Validate feeds
      run: |
        python tools/validate_feeds.py
        
    - name: Upload content validation report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: content-validation-report
        path: docs/data/validation-report.json

  frontend-validation:
    runs-on: ubuntu-latest
    name: Frontend Validation
    
    steps:
    - uses: actions/checkout@v4
      
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: docs/js/tests/package.json
        
    - name: Install dependencies
      run: |
        cd docs/js/tests
        npm ci
        
    - name: Run unit tests
      run: |
        cd docs/js/tests
        npm run test:unit
        
    - name: Run integration tests
      run: |
        cd docs/js/tests
        npm run test:integration
        
    - name: Run accessibility tests
      run: |
        cd docs/js/tests
        npm run test:a11y
        
    - name: Run performance tests
      run: |
        cd docs/js/tests
        npm run test:performance
        
    - name: Upload test coverage
      uses: codecov/codecov-action@v3
      with:
        file: docs/js/tests/coverage/lcov.info
        flags: frontend
        name: frontend-coverage
        
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: frontend-test-results
        path: docs/js/tests/reports/

  e2e-validation:
    runs-on: ubuntu-latest
    name: End-to-End Validation
    
    steps:
    - uses: actions/checkout@v4
      
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        
    - name: Install dependencies
      run: |
        cd docs/js/tests
        npm ci
        
    - name: Install Playwright
      run: |
        cd docs/js/tests
        npx playwright install
        
    - name: Start local server
      run: |
        cd docs
        python -m http.server 3000 &
        sleep 5
        
    - name: Run E2E tests
      run: |
        cd docs/js/tests
        npm run test:e2e
        
    - name: Upload E2E test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: docs/js/tests/reports/e2e/

  accessibility-audit:
    runs-on: ubuntu-latest
    name: Accessibility Audit
    
    steps:
    - uses: actions/checkout@v4
      
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        
    - name: Install lighthouse and axe
      run: |
        npm install -g @lhci/cli lighthouse axe-core
        
    - name: Start local server
      run: |
        cd docs
        python -m http.server 3000 &
        sleep 5
        
    - name: Run Lighthouse accessibility audit
      run: |
        mkdir -p reports/lighthouse
        lhci autorun --config=.lighthouserc.json || true
        
    - name: Run axe accessibility tests
      run: |
        cd docs/js/tests
        npm run test:axe
        
    - name: Upload accessibility reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: accessibility-reports
        path: reports/

  performance-audit:
    runs-on: ubuntu-latest
    name: Performance Audit
    
    steps:
    - uses: actions/checkout@v4
      
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        
    - name: Install dependencies
      run: |
        npm install -g lighthouse @lhci/cli webpack-bundle-analyzer
        
    - name: Start local server
      run: |
        cd docs
        python -m http.server 3000 &
        sleep 5
        
    - name: Run Lighthouse performance audit
      run: |
        mkdir -p reports/performance
        lighthouse http://localhost:3000 \
          --output=json \
          --output-path=reports/performance/lighthouse.json \
          --chrome-flags="--headless --no-sandbox" \
          --only-categories=performance,best-practices
          
    - name: Analyze bundle size
      run: |
        cd docs/js
        find . -name "*.js" -exec wc -c {} + > ../../reports/performance/bundle-sizes.txt
        
    - name: Validate performance thresholds
      run: |
        cd docs/js/tests
        npm run test:performance:ci
        
    - name: Upload performance reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-reports
        path: reports/performance/

  security-validation:
    runs-on: ubuntu-latest
    name: Security Validation
    
    steps:
    - uses: actions/checkout@v4
      
    - name: Run CodeQL Analysis
      uses: github/codeql-action/init@v2
      with:
        languages: javascript, python
        
    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v2
      
    - name: Security scan for dependencies
      run: |
        cd docs/js/tests
        npm audit --audit-level moderate
        
    - name: Scan for secrets
      uses: trufflesecurity/trufflehog@main
      with:
        path: ./
        base: ${{ github.event.repository.default_branch }}
        head: HEAD

  validation-summary:
    runs-on: ubuntu-latest
    name: Validation Summary
    needs: [content-validation, frontend-validation, e2e-validation, accessibility-audit, performance-audit]
    if: always()
    
    steps:
    - uses: actions/checkout@v4
      
    - name: Download all artifacts
      uses: actions/download-artifact@v3
      
    - name: Generate validation summary
      run: |
        python - << 'EOF'
        import json
        import os
        from pathlib import Path
        
        summary = {
            "timestamp": "$(date -Iseconds)",
            "commit": "${{ github.sha }}",
            "branch": "${{ github.ref_name }}",
            "results": {}
        }
        
        # Collect results from artifacts
        artifacts_dir = Path(".")
        
        # Content validation
        content_report = artifacts_dir / "content-validation-report" / "validation-report.json"
        if content_report.exists():
            with open(content_report) as f:
                summary["results"]["content"] = json.load(f)
        
        # Frontend tests
        frontend_dir = artifacts_dir / "frontend-test-results"
        if frontend_dir.exists():
            summary["results"]["frontend"] = {
                "status": "completed",
                "artifacts": list(str(p) for p in frontend_dir.glob("**/*"))
            }
        
        # Generate markdown summary
        md_content = f"""
        # ðŸ” ç»¼åˆéªŒè¯æŠ¥å‘Š
        
        **æäº¤**: `{summary["commit"][:8]}`  
        **åˆ†æ”¯**: `{summary["branch"]}`  
        **æ—¶é—´**: {summary["timestamp"]}
        
        ## ðŸ“Š éªŒè¯ç»“æžœæ¦‚è§ˆ
        
        | éªŒè¯ç±»åž‹ | çŠ¶æ€ | è¯¦æƒ… |
        |---------|------|------|
        | å†…å®¹éªŒè¯ | {'âœ…' if summary["results"].get("content", {}).get("success") else 'âŒ'} | [æŸ¥çœ‹è¯¦æƒ…](#content-validation) |
        | å‰ç«¯æµ‹è¯• | {'âœ…' if "frontend" in summary["results"] else 'âŒ'} | [æŸ¥çœ‹è¯¦æƒ…](#frontend-validation) |
        | E2Eæµ‹è¯• | {'âœ…' if needs.e2e-validation.result == 'success' else 'âŒ'} | [æŸ¥çœ‹è¯¦æƒ…](#e2e-validation) |
        | æ— éšœç¢å®¡è®¡ | {'âœ…' if needs.accessibility-audit.result == 'success' else 'âŒ'} | [æŸ¥çœ‹è¯¦æƒ…](#accessibility-audit) |
        | æ€§èƒ½å®¡è®¡ | {'âœ…' if needs.performance-audit.result == 'success' else 'âŒ'} | [æŸ¥çœ‹è¯¦æƒ…](#performance-audit) |
        
        ## ðŸ“ è¯¦ç»†æŠ¥å‘Š
        
        éªŒè¯è¯¦æƒ…è¯·æŸ¥çœ‹ä¸Šä¼ çš„æž„ä»¶ï¼ˆArtifactsï¼‰ã€‚
        """
        
        with open("validation-summary.md", "w", encoding="utf-8") as f:
            f.write(md_content)
        
        with open("validation-summary.json", "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        EOF
        
    - name: Upload validation summary
      uses: actions/upload-artifact@v3
      with:
        name: validation-summary
        path: |
          validation-summary.md
          validation-summary.json
          
    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('validation-summary.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });

  update-validation-status:
    runs-on: ubuntu-latest
    name: Update Validation Status
    needs: [validation-summary]
    if: always() && github.ref == 'refs/heads/master'
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Download validation summary
      uses: actions/download-artifact@v3
      with:
        name: validation-summary
        
    - name: Update validation badge
      run: |
        # Generate validation badge based on results
        python - << 'EOF'
        import json
        import requests
        
        try:
            with open("validation-summary.json") as f:
                summary = json.load(f)
            
            # Calculate overall status
            results = summary.get("results", {})
            total_checks = len(results)
            passed_checks = sum(1 for r in results.values() if r.get("success", False))
            
            if total_checks == 0:
                status = "unknown"
                color = "lightgrey"
            elif passed_checks == total_checks:
                status = "passing"
                color = "brightgreen"
            elif passed_checks >= total_checks * 0.7:
                status = "mostly passing"
                color = "yellow"
            else:
                status = "failing"
                color = "red"
            
            badge_url = f"https://img.shields.io/badge/validation-{status.replace(' ', '%20')}-{color}"
            
            print(f"Validation status: {status}")
            print(f"Badge URL: {badge_url}")
            
        except Exception as e:
            print(f"Error generating badge: {e}")
        EOF
        
    - name: Commit validation results
      run: |
        if [ -f validation-summary.json ]; then
          cp validation-summary.json docs/data/latest-validation.json
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add docs/data/latest-validation.json
          git commit -m "ðŸ¤– Update validation results" || exit 0
          git push
        fi